{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa029ea",
   "metadata": {},
   "source": [
    "# Face Recognition Multi-Model Training on LFW\n",
    "## Training 25 Models with Different Backbones and Classifier Heads\n",
    "\n",
    "This notebook trains multiple face identification models and compares their performance.\n",
    "- **Task**: Face Identification (multi-class classification)\n",
    "- **Models**: 5 Backbones × 5 Classifier Heads = 25 Models\n",
    "- **Output**: Best model for video face recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e3569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score,\n",
    "                             confusion_matrix, classification_report, top_k_accuracy_score)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Device setup for Kaggle dual GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_gpus = torch.cuda.device_count()\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Number of GPUs: {n_gpus}\")\n",
    "if n_gpus > 0:\n",
    "    for i in range(n_gpus):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403f3678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# KAGGLE CONFIGURATION\n",
    "# ============================================================\n",
    "# Set this to True when running on Kaggle\n",
    "RUNNING_ON_KAGGLE = True\n",
    "\n",
    "if RUNNING_ON_KAGGLE:\n",
    "    # Data is already extracted on Kaggle at this path\n",
    "    DATA_DIR = '/kaggle/input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'\n",
    "    WORK_DIR = '/kaggle/working'\n",
    "    MODELS_DIR = os.path.join(WORK_DIR, 'models')\n",
    "else:\n",
    "    # Local paths\n",
    "    WORK_DIR = '../outputs'\n",
    "    DATA_DIR = '../data/lfw-deepfunneled/lfw-deepfunneled'\n",
    "    MODELS_DIR = '../models/checkpoints'\n",
    "\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Working directory: {WORK_DIR}\")\n",
    "print(f\"Models directory: {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da640292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data exists\n",
    "if os.path.exists(DATA_DIR):\n",
    "    num_people = len([d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))])\n",
    "    print(f\"✓ Data found at {DATA_DIR}\")\n",
    "    print(f\"  Total people directories: {num_people}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Data not found at {DATA_DIR}. Please check the path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42f8131",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0de53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MIN_IMAGES_PER_PERSON = 10  # Only include people with >= N images\n",
    "MAX_PEOPLE = 100  # Limit to top N people (None for all)\n",
    "VAL_SPLIT = 0.2\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32 * max(1, n_gpus)  # Scale batch size with GPUs\n",
    "\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Min images per person: {MIN_IMAGES_PER_PERSON}\")\n",
    "print(f\"Max people: {MAX_PEOPLE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01107170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lfw_dataset(data_dir, min_images=10, max_people=None):\n",
    "    \"\"\"Load LFW dataset for face identification.\"\"\"\n",
    "    people_dirs = sorted([d for d in os.listdir(data_dir) \n",
    "                          if os.path.isdir(os.path.join(data_dir, d))])\n",
    "    \n",
    "    # Count images per person\n",
    "    person_counts = {}\n",
    "    for person in people_dirs:\n",
    "        person_path = os.path.join(data_dir, person)\n",
    "        images = [f for f in os.listdir(person_path) if f.endswith('.jpg')]\n",
    "        if len(images) >= min_images:\n",
    "            person_counts[person] = len(images)\n",
    "    \n",
    "    # Sort by count and limit\n",
    "    sorted_people = sorted(person_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    if max_people:\n",
    "        sorted_people = sorted_people[:max_people]\n",
    "    \n",
    "    # Create class mapping\n",
    "    class_names = [p[0] for p in sorted_people]\n",
    "    class_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
    "    \n",
    "    # Collect all image paths and labels\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for person in class_names:\n",
    "        person_path = os.path.join(data_dir, person)\n",
    "        images = [f for f in os.listdir(person_path) if f.endswith('.jpg')]\n",
    "        for img in images:\n",
    "            image_paths.append(os.path.join(person_path, img))\n",
    "            labels.append(class_to_idx[person])\n",
    "    \n",
    "    return image_paths, labels, class_names\n",
    "\n",
    "# Load dataset\n",
    "image_paths, labels, class_names = load_lfw_dataset(\n",
    "    DATA_DIR, \n",
    "    min_images=MIN_IMAGES_PER_PERSON,\n",
    "    max_people=MAX_PEOPLE\n",
    ")\n",
    "\n",
    "num_classes = len(class_names)\n",
    "print(f\"\\nTotal images: {len(image_paths)}\")\n",
    "print(f\"Number of classes (people): {num_classes}\")\n",
    "print(f\"\\nFirst 10 people: {class_names[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694eeef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    image_paths, labels, \n",
    "    test_size=VAL_SPLIT, \n",
    "    stratify=labels, \n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = FaceDataset(X_train, y_train, transform=train_transform)\n",
    "val_dataset = FaceDataset(X_val, y_val, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n",
    "    num_workers=4, pin_memory=True, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b4c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize samples\n",
    "def show_samples(dataset, class_names, n=8):\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
    "    indices = np.random.choice(len(dataset), n, replace=False)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        img, label = dataset[indices[i]]\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "        img = img * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        ax.imshow(img)\n",
    "        ax.set_title(class_names[label].replace('_', ' '), fontsize=10)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('Training Samples', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_samples(train_dataset, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b76d785",
   "metadata": {},
   "source": [
    "## 2. Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd5d60",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model, out_features\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Test backbone loading\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m test_backbone, test_features = \u001b[43mget_backbone\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresnet50\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResNet50 output features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m test_backbone\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mget_backbone\u001b[39m\u001b[34m(name, pretrained)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get backbone network with pretrained weights.\"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name == \u001b[33m'\u001b[39m\u001b[33mresnet50\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     model = \u001b[43mmodels\u001b[49m.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2 \u001b[38;5;28;01mif\u001b[39;00m pretrained \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m      9\u001b[39m     out_features = model.fc.in_features\n\u001b[32m     10\u001b[39m     model.fc = nn.Identity()\n",
      "\u001b[31mNameError\u001b[39m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BACKBONE DEFINITIONS\n",
    "# ============================================================\n",
    "\n",
    "def get_backbone(name, pretrained=True):\n",
    "    \"\"\"Get backbone network with pretrained weights.\"\"\"\n",
    "    if name == 'resnet50':\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2 if pretrained else None)\n",
    "        out_features = model.fc.in_features\n",
    "        model.fc = nn.Identity()\n",
    "    elif name == 'resnet101':\n",
    "        model = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V2 if pretrained else None)\n",
    "        out_features = model.fc.in_features\n",
    "        model.fc = nn.Identity()\n",
    "    elif name == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        out_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Identity()\n",
    "    elif name == 'efficientnet_b3':\n",
    "        model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        out_features = model.classifier[1].in_features\n",
    "        model.classifier = nn.Identity()\n",
    "    elif name == 'densenet121':\n",
    "        model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        out_features = model.classifier.in_features\n",
    "        model.classifier = nn.Identity()\n",
    "    elif name == 'mobilenet_v3':\n",
    "        model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.IMAGENET1K_V2 if pretrained else None)\n",
    "        out_features = model.classifier[0].in_features\n",
    "        model.classifier = nn.Identity()\n",
    "    elif name == 'convnext_tiny':\n",
    "        model = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "        out_features = model.classifier[2].in_features\n",
    "        # Keep LayerNorm2d and Flatten, only remove the Linear layer\n",
    "        model.classifier = nn.Sequential(\n",
    "            model.classifier[0],  # LayerNorm2d\n",
    "            model.classifier[1],  # Flatten\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown backbone: {name}\")\n",
    "    \n",
    "    return model, out_features\n",
    "\n",
    "# Test backbone loading\n",
    "test_backbone, test_features = get_backbone('resnet50')\n",
    "print(f\"ResNet50 output features: {test_features}\")\n",
    "del test_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4f3f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CLASSIFIER HEAD DEFINITIONS\n",
    "# ============================================================\n",
    "\n",
    "class SimpleHead(nn.Module):\n",
    "    \"\"\"Simple linear classifier head.\"\"\"\n",
    "    def __init__(self, in_features, num_classes, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.head(x)\n",
    "\n",
    "class MLPHead(nn.Module):\n",
    "    \"\"\"Multi-layer perceptron head.\"\"\"\n",
    "    def __init__(self, in_features, num_classes, hidden_dim=512, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.head(x)\n",
    "\n",
    "class DeepHead(nn.Module):\n",
    "    \"\"\"Deep MLP head with 2 hidden layers.\"\"\"\n",
    "    def __init__(self, in_features, num_classes, hidden_dim=512, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.BatchNorm1d(hidden_dim // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout / 2),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.head(x)\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    \"\"\"Attention-based classifier head.\"\"\"\n",
    "    def __init__(self, in_features, num_classes, hidden_dim=512, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # For 1D features, attention simplifies to weighted FC\n",
    "        return self.fc(x)\n",
    "\n",
    "class CosFaceHead(nn.Module):\n",
    "    \"\"\"CosFace/ArcFace style head with normalized weights.\"\"\"\n",
    "    def __init__(self, in_features, num_classes, hidden_dim=512, dropout=0.5, s=30.0, m=0.35):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(in_features, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(num_classes, hidden_dim))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "    \n",
    "    def forward(self, x, labels=None):\n",
    "        x = self.projection(x)\n",
    "        # Normalize features and weights\n",
    "        x_norm = F.normalize(x, p=2, dim=1)\n",
    "        w_norm = F.normalize(self.weight, p=2, dim=1)\n",
    "        # Cosine similarity\n",
    "        cosine = F.linear(x_norm, w_norm)\n",
    "        # Scale\n",
    "        output = self.s * cosine\n",
    "        return output\n",
    "\n",
    "# Head factory\n",
    "def get_head(name, in_features, num_classes, dropout=0.5):\n",
    "    \"\"\"Get classifier head by name.\"\"\"\n",
    "    heads = {\n",
    "        'simple': SimpleHead,\n",
    "        'mlp': MLPHead,\n",
    "        'deep': DeepHead,\n",
    "        'attention': AttentionHead,\n",
    "        'cosface': CosFaceHead\n",
    "    }\n",
    "    if name not in heads:\n",
    "        raise ValueError(f\"Unknown head: {name}\")\n",
    "    return heads[name](in_features, num_classes, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe36d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# COMPLETE FACE CLASSIFIER MODEL\n",
    "# ============================================================\n",
    "\n",
    "class FaceClassifier(nn.Module):\n",
    "    \"\"\"Face identification model with configurable backbone and head.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, backbone_name='resnet50', head_name='mlp', \n",
    "                 pretrained=True, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.backbone_name = backbone_name\n",
    "        self.head_name = head_name\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Load backbone\n",
    "        self.backbone, out_features = get_backbone(backbone_name, pretrained)\n",
    "        \n",
    "        # Create classifier head\n",
    "        self.head = get_head(head_name, out_features, num_classes, dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        if isinstance(features, tuple):\n",
    "            features = features[0]\n",
    "        return self.head(features)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"Get predictions and probabilities.\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            preds = logits.argmax(dim=1)\n",
    "        return preds, probs\n",
    "\n",
    "# Test model creation\n",
    "test_model = FaceClassifier(num_classes=100, backbone_name='resnet50', head_name='mlp')\n",
    "print(f\"Model parameters: {sum(p.numel() for p in test_model.parameters()):,}\")\n",
    "del test_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589da4a5",
   "metadata": {},
   "source": [
    "## 3. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e49b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, scaler, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast(device_type='cuda'):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100.0 * correct / total\n",
    "\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            with autocast(device_type='cuda'):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    accuracy = 100.0 * correct / total\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_probs = np.array(all_probs)\n",
    "    \n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    top5_acc = top_k_accuracy_score(all_labels, all_probs, k=5) * 100\n",
    "    \n",
    "    return total_loss / len(loader), accuracy, f1, top5_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee6e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(backbone_name, head_name, train_loader, val_loader, \n",
    "                num_classes, epochs=1, lr=1e-4, device='cuda'):\n",
    "    \"\"\"Train a single model configuration.\"\"\"\n",
    "    model_name = f\"{backbone_name}_{head_name}\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = FaceClassifier(\n",
    "        num_classes=num_classes,\n",
    "        backbone_name=backbone_name,\n",
    "        head_name=head_name,\n",
    "        pretrained=True,\n",
    "        dropout=0.5\n",
    "    )\n",
    "    \n",
    "    # Multi-GPU support\n",
    "    if n_gpus > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Training setup\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=lr/100)\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': [],\n",
    "        'val_f1': [], 'val_top5': []\n",
    "    }\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Training loop\n",
    "    pbar = tqdm(range(epochs), desc=f\"Training {model_name}\")\n",
    "    for epoch in pbar:\n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scaler, device)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc, val_f1, val_top5 = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        history['val_top5'].append(val_top5)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model\n",
    "            best_model_state = model_to_save.state_dict().copy()\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f\"{train_loss:.4f}\",\n",
    "            'acc': f\"{train_acc:.1f}%\",\n",
    "            'val_acc': f\"{val_acc:.1f}%\",\n",
    "            'top5': f\"{val_top5:.1f}%\"\n",
    "        })\n",
    "    \n",
    "    # Final results\n",
    "    results = {\n",
    "        'model_name': model_name,\n",
    "        'backbone': backbone_name,\n",
    "        'head': head_name,\n",
    "        'best_val_acc': best_acc,\n",
    "        'final_val_acc': history['val_acc'][-1],\n",
    "        'final_val_f1': history['val_f1'][-1],\n",
    "        'final_val_top5': history['val_top5'][-1],\n",
    "        'final_train_acc': history['train_acc'][-1],\n",
    "        'history': history\n",
    "    }\n",
    "    \n",
    "    print(f\"  Best Val Accuracy: {best_acc:.2f}%\")\n",
    "    print(f\"  Final Top-5 Accuracy: {val_top5:.2f}%\")\n",
    "    \n",
    "    return results, best_model_state, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec4c48",
   "metadata": {},
   "source": [
    "## 4. Train All 25 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e0913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MODEL CONFIGURATIONS\n",
    "# ============================================================\n",
    "\n",
    "BACKBONES = ['resnet50', 'efficientnet_b0', 'densenet121', 'mobilenet_v3', 'convnext_tiny']\n",
    "HEADS = ['simple', 'mlp', 'deep', 'attention', 'cosface']\n",
    "\n",
    "# Training hyperparameters\n",
    "EPOCHS = 1  # Set to 1 for quick testing, increase to 10-20 for full training\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "print(f\"Total models to train: {len(BACKBONES)} x {len(HEADS)} = {len(BACKBONES) * len(HEADS)}\")\n",
    "print(f\"\\nBackbones: {BACKBONES}\")\n",
    "print(f\"Heads: {HEADS}\")\n",
    "print(f\"\\nEpochs: {EPOCHS}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b83ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models\n",
    "all_results = {}\n",
    "all_model_states = {}\n",
    "\n",
    "total_models = len(BACKBONES) * len(HEADS)\n",
    "current_model = 0\n",
    "\n",
    "for backbone_name in BACKBONES:\n",
    "    for head_name in HEADS:\n",
    "        current_model += 1\n",
    "        print(f\"\\n[{current_model}/{total_models}] Training {backbone_name} + {head_name}\")\n",
    "        \n",
    "        try:\n",
    "            results, model_state, model = train_model(\n",
    "                backbone_name=backbone_name,\n",
    "                head_name=head_name,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                num_classes=num_classes,\n",
    "                epochs=EPOCHS,\n",
    "                lr=LEARNING_RATE,\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            model_name = f\"{backbone_name}_{head_name}\"\n",
    "            all_results[model_name] = results\n",
    "            all_model_states[model_name] = model_state\n",
    "            \n",
    "            # Save individual model\n",
    "            save_path = os.path.join(MODELS_DIR, f\"{model_name}.pt\")\n",
    "            torch.save({\n",
    "                'model_state_dict': model_state,\n",
    "                'backbone': backbone_name,\n",
    "                'head': head_name,\n",
    "                'num_classes': num_classes,\n",
    "                'class_names': class_names,\n",
    "                'results': results\n",
    "            }, save_path)\n",
    "            print(f\"  Saved to {save_path}\")\n",
    "            \n",
    "            # Clean up\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training complete! {len(all_results)} models trained successfully.\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9f875d",
   "metadata": {},
   "source": [
    "## 5. Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55635a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame\n",
    "results_data = []\n",
    "for name, res in all_results.items():\n",
    "    results_data.append({\n",
    "        'Model': name,\n",
    "        'Backbone': res['backbone'],\n",
    "        'Head': res['head'],\n",
    "        'Train Acc': res['final_train_acc'],\n",
    "        'Val Acc': res['final_val_acc'],\n",
    "        'Best Val Acc': res['best_val_acc'],\n",
    "        'Val F1': res['final_val_f1'],\n",
    "        'Top-5 Acc': res['final_val_top5']\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df = results_df.sort_values('Best Val Acc', ascending=False)\n",
    "\n",
    "print(\"\\nAll Models Ranked by Validation Accuracy:\")\n",
    "print(\"=\"*80)\n",
    "display(results_df.style.highlight_max(subset=['Train Acc', 'Val Acc', 'Best Val Acc', 'Val F1', 'Top-5 Acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eea6c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Validation Accuracy by Model\n",
    "ax = axes[0, 0]\n",
    "sorted_results = results_df.sort_values('Best Val Acc', ascending=True)\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(sorted_results)))\n",
    "ax.barh(sorted_results['Model'], sorted_results['Best Val Acc'], color=colors)\n",
    "ax.set_xlabel('Validation Accuracy (%)')\n",
    "ax.set_title('Model Comparison by Validation Accuracy')\n",
    "ax.axvline(sorted_results['Best Val Acc'].mean(), color='red', linestyle='--', label='Mean')\n",
    "ax.legend()\n",
    "\n",
    "# 2. Backbone Comparison\n",
    "ax = axes[0, 1]\n",
    "backbone_avg = results_df.groupby('Backbone')['Best Val Acc'].mean().sort_values(ascending=False)\n",
    "ax.bar(backbone_avg.index, backbone_avg.values, color='steelblue')\n",
    "ax.set_ylabel('Average Validation Accuracy (%)')\n",
    "ax.set_title('Average Performance by Backbone')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "for i, v in enumerate(backbone_avg.values):\n",
    "    ax.text(i, v + 0.5, f'{v:.1f}%', ha='center')\n",
    "\n",
    "# 3. Head Comparison\n",
    "ax = axes[1, 0]\n",
    "head_avg = results_df.groupby('Head')['Best Val Acc'].mean().sort_values(ascending=False)\n",
    "ax.bar(head_avg.index, head_avg.values, color='darkorange')\n",
    "ax.set_ylabel('Average Validation Accuracy (%)')\n",
    "ax.set_title('Average Performance by Classifier Head')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "for i, v in enumerate(head_avg.values):\n",
    "    ax.text(i, v + 0.5, f'{v:.1f}%', ha='center')\n",
    "\n",
    "# 4. Heatmap\n",
    "ax = axes[1, 1]\n",
    "pivot_df = results_df.pivot(index='Backbone', columns='Head', values='Best Val Acc')\n",
    "sns.heatmap(pivot_df, annot=True, fmt='.1f', cmap='YlOrRd', ax=ax, cbar_kws={'label': 'Accuracy (%)'})\n",
    "ax.set_title('Backbone × Head Performance Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(WORK_DIR, 'model_comparison.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ae1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves for top 5 models\n",
    "top_5_models = results_df.head(5)['Model'].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for model_name in top_5_models:\n",
    "    history = all_results[model_name]['history']\n",
    "    axes[0].plot(history['train_loss'], label=f\"{model_name} (train)\")\n",
    "    axes[0].plot(history['val_loss'], '--', label=f\"{model_name} (val)\")\n",
    "\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training Loss - Top 5 Models')\n",
    "axes[0].legend(fontsize=8)\n",
    "\n",
    "for model_name in top_5_models:\n",
    "    history = all_results[model_name]['history']\n",
    "    axes[1].plot(history['val_acc'], label=model_name)\n",
    "\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Validation Accuracy (%)')\n",
    "axes[1].set_title('Validation Accuracy - Top 5 Models')\n",
    "axes[1].legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(WORK_DIR, 'training_curves_top5.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3cf9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model summary\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_results = all_results[best_model_name]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST MODEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model:           {best_model_name}\")\n",
    "print(f\"Backbone:        {best_results['backbone']}\")\n",
    "print(f\"Classifier Head: {best_results['head']}\")\n",
    "print(f\"\")\n",
    "print(f\"Training Accuracy:    {best_results['final_train_acc']:.2f}%\")\n",
    "print(f\"Validation Accuracy:  {best_results['best_val_acc']:.2f}%\")\n",
    "print(f\"Top-5 Accuracy:       {best_results['final_val_top5']:.2f}%\")\n",
    "print(f\"F1 Score:             {best_results['final_val_f1']:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3dca25",
   "metadata": {},
   "source": [
    "## 6. Save Best Model for Video Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e3a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model in the format compatible with video inference\n",
    "best_model_path = os.path.join(MODELS_DIR, 'best_face_recognition.pt')\n",
    "\n",
    "best_save_dict = {\n",
    "    'model_state_dict': all_model_states[best_model_name],\n",
    "    'backbone': best_results['backbone'],\n",
    "    'head': best_results['head'],\n",
    "    'num_classes': num_classes,\n",
    "    'class_names': class_names,\n",
    "    'best_val_acc': best_results['best_val_acc'],\n",
    "    'results': best_results\n",
    "}\n",
    "\n",
    "torch.save(best_save_dict, best_model_path)\n",
    "print(f\"Best model saved to: {best_model_path}\")\n",
    "\n",
    "# Also save class names as JSON\n",
    "class_names_path = os.path.join(MODELS_DIR, 'class_names.json')\n",
    "with open(class_names_path, 'w') as f:\n",
    "    json.dump(class_names, f, indent=2)\n",
    "print(f\"Class names saved to: {class_names_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c831f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results as JSON\n",
    "all_results_json = []\n",
    "for name, res in all_results.items():\n",
    "    all_results_json.append({\n",
    "        'model_name': name,\n",
    "        'backbone': res['backbone'],\n",
    "        'head': res['head'],\n",
    "        'best_val_acc': res['best_val_acc'],\n",
    "        'final_val_acc': res['final_val_acc'],\n",
    "        'final_val_f1': res['final_val_f1'],\n",
    "        'final_val_top5': res['final_val_top5'],\n",
    "        'final_train_acc': res['final_train_acc'],\n",
    "        'history': {\n",
    "            'train_loss': res['history']['train_loss'],\n",
    "            'train_acc': res['history']['train_acc'],\n",
    "            'val_loss': res['history']['val_loss'],\n",
    "            'val_acc': res['history']['val_acc']\n",
    "        }\n",
    "    })\n",
    "\n",
    "results_path = os.path.join(WORK_DIR, 'all_model_results.json')\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(all_results_json, f, indent=2)\n",
    "print(f\"All results saved to: {results_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6fbbb1",
   "metadata": {},
   "source": [
    "## 7. Test Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6822f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FaceClassifier(nn.Module):\n",
    "    \"\"\"Face identification model with configurable backbone and head.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, backbone_name='resnet50', head_name='mlp', \n",
    "                 pretrained=True, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.backbone_name = backbone_name\n",
    "        self.head_name = head_name\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Load backbone\n",
    "        self.backbone, out_features = get_backbone(backbone_name, pretrained)\n",
    "        \n",
    "        # Create classifier head\n",
    "        self.head = get_head(head_name, out_features, num_classes, dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        if isinstance(features, tuple):\n",
    "            features = features[0]\n",
    "        return self.head(features)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"Get predictions and probabilities.\"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(x)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            preds = logits.argmax(dim=1)\n",
    "        return preds, probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07e482e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_backbone' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model, checkpoint[\u001b[33m'\u001b[39m\u001b[33mclass_names\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Load model (use existing best_model_path and device)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m best_model, loaded_class_names = \u001b[43mload_best_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest model loaded successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(loaded_class_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mload_best_model\u001b[39m\u001b[34m(checkpoint_path, device)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Use weights_only=False for trusted checkpoints saved with extra metadata\u001b[39;00m\n\u001b[32m      5\u001b[39m checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mFaceClassifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnum_classes\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackbone_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbackbone\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhead\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m model.load_state_dict(checkpoint[\u001b[33m'\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     14\u001b[39m model = model.to(device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mFaceClassifier.__init__\u001b[39m\u001b[34m(self, num_classes, backbone_name, head_name, pretrained, dropout)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mself\u001b[39m.num_classes = num_classes\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Load backbone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28mself\u001b[39m.backbone, out_features = \u001b[43mget_backbone\u001b[49m(backbone_name, pretrained)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Create classifier head\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.head = get_head(head_name, out_features, num_classes, dropout)\n",
      "\u001b[31mNameError\u001b[39m: name 'get_backbone' is not defined"
     ]
    }
   ],
   "source": [
    "# Load and test best model\n",
    "def load_best_model(checkpoint_path, device):\n",
    "    \"\"\"Load the best model from checkpoint.\"\"\"\n",
    "    # Use weights_only=False for trusted checkpoints saved with extra metadata\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    model = FaceClassifier(\n",
    "        num_classes=checkpoint['num_classes'],\n",
    "        backbone_name=checkpoint['backbone'],\n",
    "        head_name=checkpoint['head'],\n",
    "        pretrained=False\n",
    "    )\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, checkpoint['class_names']\n",
    "\n",
    "# Load model (use existing best_model_path and device)\n",
    "best_model, loaded_class_names = load_best_model(best_model_path, device)\n",
    "print(f\"Best model loaded successfully!\")\n",
    "print(f\"Number of classes: {len(loaded_class_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db64125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "best_model.eval()\n",
    "images, labels = next(iter(val_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "preds, probs = best_model.predict(images)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "    img = img * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406]\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    pred_name = class_names[preds[i].item()].replace('_', ' ')\n",
    "    true_name = class_names[labels[i].item()].replace('_', ' ')\n",
    "    conf = probs[i, preds[i]].item()\n",
    "    \n",
    "    color = 'green' if preds[i].item() == labels[i].item() else 'red'\n",
    "    ax.set_title(f'Pred: {pred_name}\\nTrue: {true_name}\\nConf: {conf:.2%}', color=color, fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle(f'Best Model Predictions ({best_model_name})', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(WORK_DIR, 'best_model_predictions.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59059396",
   "metadata": {},
   "source": [
    "## 8. Usage for Video Inference\n",
    "\n",
    "The saved model is compatible with the video face recognition pipeline.\n",
    "\n",
    "```python\n",
    "# Load model for video inference\n",
    "import torch\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load('models/best_face_recognition.pt')\n",
    "\n",
    "# Create model\n",
    "model = FaceClassifier(\n",
    "    num_classes=checkpoint['num_classes'],\n",
    "    backbone_name=checkpoint['backbone'],\n",
    "    head_name=checkpoint['head'],\n",
    "    pretrained=False\n",
    ")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Face detector\n",
    "mtcnn = MTCNN(keep_all=True, device='cuda')\n",
    "\n",
    "# Use with VideoFaceRecognizer from video_face_recognition.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal models trained: {len(all_results)}\")\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Best accuracy: {best_results['best_val_acc']:.2f}%\")\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"  - {best_model_path}\")\n",
    "print(f\"  - {class_names_path}\")\n",
    "print(f\"  - {results_path}\")\n",
    "print(f\"  - Individual model checkpoints in {MODELS_DIR}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
